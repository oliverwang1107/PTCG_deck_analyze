"""
PTCG é€²éšçµ±è¨ˆåˆ†æå„€è¡¨æ¿ â€” Streamlit App

Launch:  python -m src.main stats
"""
from __future__ import annotations

import json
from pathlib import Path
from typing import Any

import pandas as pd
import streamlit as st

# â”€â”€ Page Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="PTCG çµ±è¨ˆåˆ†æ",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded",
)

# â”€â”€ Data & Translation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_DIR = Path("data")


@st.cache_data(ttl=300)
def load_data() -> dict | None:
    """Load cached tournament data."""
    path = DATA_DIR / "scraped_data.json"
    if not path.exists():
        return None
    return json.loads(path.read_text(encoding="utf-8"))


def _init_translate():
    """Return archetype â†’ Chinese translation function."""
    try:
        from src.translation import translate_archetype
        return translate_archetype
    except ImportError:
        return lambda x: x


data = load_data()
if data is None:
    st.error("âŒ æ‰¾ä¸åˆ°è³‡æ–™ï¼è«‹å…ˆåŸ·è¡Œ `python -m src.main scrape` æŠ“å–è³‡æ–™ã€‚")
    st.stop()

zh = _init_translate()

from src.analyzer.statistics import StatisticalAnalyzer  # noqa: E402

analyzer = StatisticalAnalyzer(data)

# â”€â”€ Sidebar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.title("ğŸ“ çµ±è¨ˆåˆ†æ")
st.sidebar.markdown("---")

min_entries = st.sidebar.slider("æœ€ä½æ¨£æœ¬æ•¸", 3, 20, 5, help="ä½æ–¼æ­¤æ•¸é‡çš„ç‰Œçµ„å°‡è¢«æ’é™¤")

SECTIONS = [
    "ğŸ“Š ç¸½è¦½",
    "ğŸ¯ è²æ°å‹ç‡",
    "ğŸ“ˆ ç’°å¢ƒç©©å®šæ€§",
    "ğŸ”„ Meta æ¼‚ç§»åµæ¸¬",
    "ğŸ›ï¸ é›†ä¸­åº¦åˆ†æ",
    "ğŸ’° æœŸæœ›å€¼ (EV)",
    "âš”ï¸ åŒ¹é…é¡¯è‘—æ€§",
]
section = st.sidebar.radio("åˆ†æé …ç›®", SECTIONS)

st.sidebar.markdown("---")
st.sidebar.caption(
    "æ‰€æœ‰çµ±è¨ˆæ–¹æ³•å‡ä½¿ç”¨ç§‘å­¸ç´šæ¼”ç®—æ³•ï¼Œ"
    "åŒ…å«æ­£ç¢ºçš„ä¿¡è³´/å¯ä¿¡å€é–“ã€å‡è¨­æª¢å®šèˆ‡æ ¡æ­£ã€‚"
)


# â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _make_df(rows: list[dict[str, Any]], *, name_col: str = "name") -> pd.DataFrame:
    """Build a DataFrame and add a translated name column."""
    df = pd.DataFrame(rows)
    if name_col in df.columns:
        df.insert(0, "ç‰Œçµ„", df[name_col].map(zh))
    return df


def _show_empty() -> None:
    st.warning("æ²’æœ‰è¶³å¤ è³‡æ–™ï¼ˆè«‹èª¿ä½æœ€ä½æ¨£æœ¬æ•¸æˆ–ç¢ºèªè³‡æ–™å·²æŠ“å–ï¼‰")


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  Sections
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

if section == "ğŸ“Š ç¸½è¦½":
    st.title("ğŸ“Š çµ±è¨ˆåˆ†æç¸½è¦½")

    col_left, col_right = st.columns(2)

    # â”€â”€ Concentration snapshot â”€â”€
    with col_left:
        st.subheader("ğŸ›ï¸ ç’°å¢ƒé›†ä¸­åº¦")
        conc = analyzer.concentration_indices()
        if "error" not in conc:
            c1, c2, c3 = st.columns(3)
            c1.metric("Simpson's", conc["simpsons_index"],
                       help="1 = å®Œå…¨å¤šå…ƒ, 0 = å®Œå…¨é›†ä¸­")
            c2.metric("Shannon", conc["shannon_entropy"],
                       help="è³‡è¨Šç†µï¼Œè¶Šé«˜è¶Šå¤šå…ƒ")
            c3.metric("HHI", conc["hhi"],
                       help="< 0.15 = ç«¶çˆ­æ€§ç’°å¢ƒ")
            st.caption(
                f"æœ‰æ•ˆç‰©ç¨®æ•¸ {conc['effective_species']} Â· "
                f"å‡å‹»åº¦ {conc['evenness']} Â· "
                f"ç‰Œçµ„ç¨®é¡ {conc['species_richness']}"
            )
        else:
            st.info("é›†ä¸­åº¦è³‡æ–™ä¸è¶³")

    # â”€â”€ Meta shift snapshot â”€â”€
    with col_right:
        st.subheader("ğŸ”„ ç’°å¢ƒè®ŠåŒ–åµæ¸¬")
        shift = analyzer.meta_shift_test()
        if shift["result"] == "complete":
            st.metric(
                f"{shift['previous_week']} â†’ {shift['current_week']}",
                shift["interpretation"],
            )
            st.caption(
                f"Ï‡Â² = {shift['chi_square']} Â· "
                f"df = {shift['degrees_of_freedom']} Â· "
                f"p = {shift['p_value']}"
            )
        else:
            st.info(shift.get("message", "è³‡æ–™ä¸è¶³"))

    st.markdown("---")

    # â”€â”€ Top Bayesian win rates â”€â”€
    st.subheader("ğŸ¯ è²æ°å‹ç‡ Top 10")
    bayes = analyzer.bayesian_win_rates(min_entries)[:10]
    if bayes:
        df = _make_df(bayes)
        st.dataframe(
            df[["ç‰Œçµ„", "posterior_mean", "ci_low", "ci_high", "sample_size"]]
            .rename(columns={
                "posterior_mean": "è²æ°å‹ç‡ %",
                "ci_low": "95% CI ä¸‹é™",
                "ci_high": "95% CI ä¸Šé™",
                "sample_size": "æ¨£æœ¬æ•¸",
            }),
            use_container_width=True, hide_index=True,
        )
    else:
        _show_empty()

    # â”€â”€ Top EV â”€â”€
    st.subheader("ğŸ’° æœŸæœ›å€¼ Top 10")
    ev = analyzer.ev_analysis(min_entries)[:10]
    if ev:
        df = _make_df(ev)
        st.dataframe(
            df[["ç‰Œçµ„", "ev", "std", "sharpe", "deck_count"]]
            .rename(columns={
                "ev": "EV (pts)",
                "std": "Std Dev",
                "sharpe": "Sharpe",
                "deck_count": "æ¨£æœ¬æ•¸",
            }),
            use_container_width=True, hide_index=True,
        )
    else:
        _show_empty()


elif section == "ğŸ¯ è²æ°å‹ç‡":
    st.title("ğŸ¯ è²æ°å‹ç‡ä¼°è¨ˆ (Beta-Binomial)")

    st.info(
        "**æ–¹æ³•**ï¼šä½¿ç”¨ Beta(2, 2) å¼±è³‡è¨Šå…ˆé©—ï¼Œçµåˆè§€æ¸¬è³‡æ–™è¨ˆç®—å¾Œé©—åˆ†ä½ˆã€‚\n\n"
        "**å„ªé»**ï¼šå°æ¨£æœ¬æ™‚ä¸æœƒç”¢ç”Ÿæ¥µç«¯ä¼°è¨ˆï¼ˆå¦‚ 0 % æˆ– 100 %ï¼‰ï¼Œ"
        "å¯ä¿¡å€é–“å¯¬åº¦å¦‚å¯¦åæ˜ è³‡æ–™çš„ä¸ç¢ºå®šæ€§ã€‚"
    )

    results = analyzer.bayesian_win_rates(min_entries)
    if not results:
        _show_empty()
        st.stop()

    df = _make_df(results)

    # â”€â”€ Chart â”€â”€
    st.subheader("95 % å¯ä¿¡å€é–“ï¼ˆå‰ 20 åï¼‰")
    top = df.head(20).sort_values("posterior_mean")
    st.bar_chart(top.set_index("ç‰Œçµ„")[["posterior_mean"]], use_container_width=True)

    # â”€â”€ Full table â”€â”€
    st.subheader("å®Œæ•´è³‡æ–™")
    st.dataframe(
        df[["ç‰Œçµ„", "observed_win_rate", "posterior_mean",
            "ci_low", "ci_high", "ci_width", "wins", "sample_size"]]
        .rename(columns={
            "observed_win_rate": "è§€æ¸¬å‹ç‡ %",
            "posterior_mean": "è²æ°å‹ç‡ %",
            "ci_low": "CI ä¸‹é™",
            "ci_high": "CI ä¸Šé™",
            "ci_width": "CI å¯¬åº¦",
            "wins": "å„ªå‹æ¬¡æ•¸",
            "sample_size": "æ¨£æœ¬æ•¸",
        }),
        use_container_width=True, hide_index=True,
    )

    st.caption(
        "CI å¯¬åº¦è¶Šå° ï¼ ä¼°è¨ˆè¶Šç²¾ç¢ºï¼ˆæ¨£æœ¬è¶Šå¤šï¼‰ã€‚"
        "è²æ°å‹ç‡å‘å…ˆé©—å‡å€¼æ”¶ç¸®ï¼Œé˜²æ­¢å°æ¨£æœ¬åå·®ã€‚"
    )


elif section == "ğŸ“ˆ ç’°å¢ƒç©©å®šæ€§":
    st.title("ğŸ“ˆ ç’°å¢ƒç©©å®šæ€§åˆ†æ (Coefficient of Variation)")

    st.info(
        "**CVï¼ˆè®Šç•°ä¿‚æ•¸ï¼‰**ï¼ æ¨™æº–å·® / å¹³å‡å€¼ Ã— 100 %\n\n"
        "ä½ CV â†’ ç©©å®šå‡ºç¾åœ¨ç’°å¢ƒä¸­ï¼›é«˜ CV â†’ ä½¿ç”¨ç‡å¤§å¹…æ³¢å‹•ã€‚"
    )

    results = analyzer.meta_stability(min_entries)
    if not results:
        st.warning("éœ€è¦è‡³å°‘å…©é€±çš„è³‡æ–™")
        st.stop()

    df = _make_df(results)

    # â”€â”€ Scatter â”€â”€
    st.subheader("ç©©å®šæ€§ vs ä½¿ç”¨ç‡")
    scatter = df[["ç‰Œçµ„", "cv", "mean_share", "deck_count"]].copy()
    scatter.columns = ["ç‰Œçµ„", "CV (%)", "å¹³å‡ä½¿ç”¨ç‡ (%)", "ç¸½å¥—æ•¸"]
    st.scatter_chart(scatter, x="å¹³å‡ä½¿ç”¨ç‡ (%)", y="CV (%)", size="ç¸½å¥—æ•¸",
                     use_container_width=True)

    # â”€â”€ Table â”€â”€
    st.subheader("å®Œæ•´è³‡æ–™")
    st.dataframe(
        df[["ç‰Œçµ„", "mean_share", "std_share", "cv", "stability_label", "deck_count"]]
        .rename(columns={
            "mean_share": "å¹³å‡ä½¿ç”¨ç‡ %",
            "std_share": "æ¨™æº–å·®",
            "cv": "CV %",
            "stability_label": "ç©©å®šæ€§",
            "deck_count": "ç¸½å¥—æ•¸",
        }),
        use_container_width=True, hide_index=True,
    )


elif section == "ğŸ”„ Meta æ¼‚ç§»åµæ¸¬":
    st.title("ğŸ”„ Meta æ¼‚ç§»åµæ¸¬ (Chi-Square Test)")

    st.info(
        "**å¡æ–¹é©åˆåº¦æª¢å®š**ï¼šæ¯”è¼ƒæœ¬é€±èˆ‡ä¸Šé€±çš„ç‰Œçµ„åˆ†ä½ˆã€‚\n\n"
        "Hâ‚€ï¼šå…©é€±åˆ†ä½ˆç›¸åŒã€‚è‹¥ p < 0.05 å‰‡æ‹’çµ• Hâ‚€ï¼Œè¡¨ç¤ºç’°å¢ƒæœ‰é¡¯è‘—è®ŠåŒ–ã€‚"
    )

    result = analyzer.meta_shift_test()
    if result["result"] != "complete":
        st.warning(result.get("message", "è³‡æ–™ä¸è¶³"))
        st.stop()

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Ï‡Â² çµ±è¨ˆé‡", result["chi_square"])
    c2.metric("è‡ªç”±åº¦", result["degrees_of_freedom"])
    c3.metric("p-value", result["p_value"])
    c4.metric("åˆ¤å®š", result["interpretation"])

    st.subheader("è®ŠåŒ–æœ€å¤§çš„ç‰Œçµ„")
    if result["top_shifts"]:
        sdf = pd.DataFrame(result["top_shifts"])
        sdf.insert(0, "ç‰Œçµ„", sdf["archetype"].map(zh))
        st.dataframe(
            sdf[["ç‰Œçµ„", "observed", "expected", "contribution", "direction"]]
            .rename(columns={
                "observed": "æœ¬é€±æ•¸é‡",
                "expected": "é æœŸæ•¸é‡",
                "contribution": "Ï‡Â² è²¢ç»",
                "direction": "æ–¹å‘",
            }),
            use_container_width=True, hide_index=True,
        )

    st.caption(
        f"æœ¬é€± {result['total_current']} å¥— Â· ä¸Šé€± {result['total_previous']} å¥—"
    )


elif section == "ğŸ›ï¸ é›†ä¸­åº¦åˆ†æ":
    st.title("ğŸ›ï¸ ç’°å¢ƒé›†ä¸­åº¦åˆ†æ")

    st.info(
        "ä¸‰ç¨®äº’è£œçš„å¤šå…ƒåŒ–æŒ‡æ¨™ï¼š\n"
        "- **Simpson's Index**ï¼šéš¨æ©ŸæŠ½å…©å€‹ç‰Œçµ„å±¬æ–¼ä¸åŒåŸå‹çš„æ©Ÿç‡\n"
        "- **Shannon Entropy**ï¼šè³‡è¨Šç†è«–çš„å¤šå…ƒåŒ–æŒ‡æ¨™\n"
        "- **HHI**ï¼šèµ«èŠ¬é”çˆ¾æŒ‡æ•¸ï¼Œå¸¸ç”¨æ–¼å¸‚å ´é›†ä¸­åº¦åˆ†æ"
    )

    conc = analyzer.concentration_indices()
    if "error" in conc:
        _show_empty()
        st.stop()

    # â”€â”€ Core metrics â”€â”€
    st.subheader("æ ¸å¿ƒæŒ‡æ¨™")
    c1, c2, c3 = st.columns(3)
    with c1:
        st.metric("Simpson's Diversity", f"{conc['simpsons_index']:.4f}")
        st.caption(f"åˆ¤å®šï¼š{conc['interpretation']['simpsons']}")
    with c2:
        st.metric("Shannon Entropy", f"{conc['shannon_entropy']:.4f}")
        st.caption(f"æœ€å¤§å¯èƒ½å€¼ï¼š{conc['max_shannon']:.4f}")
    with c3:
        st.metric("HHI", f"{conc['hhi']:.4f}")
        st.caption(f"åˆ¤å®šï¼š{conc['interpretation']['hhi']}")

    st.markdown("---")

    # â”€â”€ Detail metrics â”€â”€
    st.subheader("è©³ç´°æ•¸æ“š")
    d1, d2, d3, d4 = st.columns(4)
    d1.metric("å‡å‹»åº¦ (Evenness)", f"{conc['evenness']:.4f}",
              help="H / H_max â€” 1 = å®Œå…¨å‡å‹»")
    d2.metric("æœ‰æ•ˆç‰©ç¨®æ•¸", f"{conc['effective_species']:.1f}",
              help="exp(Shannon)")
    d3.metric("ç¬¬ä¸€åä½”æ¯”", f"{conc['dominance_pct']} %")
    d4.metric("å‰ä¸‰åä½”æ¯”", f"{conc['top3_pct']} %")

    st.caption(
        f"å‡å‹»åº¦åˆ¤å®šï¼š{conc['interpretation']['evenness']} Â· "
        f"å‰äº”åä½”æ¯” {conc['top5_pct']} % Â· "
        f"ç‰Œçµ„ç¨®é¡ {conc['species_richness']} Â· "
        f"ç¸½å¥—æ•¸ {conc['total_decks']}"
    )

    # â”€â”€ Wilson CI â”€â”€
    st.markdown("---")
    st.subheader("ğŸ“ Wilson Score ä¿¡è³´å€é–“ï¼ˆTop Cut ç‡ï¼‰")
    st.caption("æ¯”å‚³çµ± Wald å€é–“æ›´æº–ç¢ºçš„å°æ¨£æœ¬ä¿¡è³´å€é–“")

    wilson = analyzer.wilson_ci(min_entries)
    if wilson:
        wdf = _make_df(wilson)
        st.dataframe(
            wdf[["ç‰Œçµ„", "win_rate", "win_rate_ci_low", "win_rate_ci_high",
                 "top8_rate", "top8_rate_ci_low", "top8_rate_ci_high", "deck_count"]]
            .head(20)
            .rename(columns={
                "win_rate": "å‹ç‡ %",
                "win_rate_ci_low": "å‹ç‡ CIâ†“",
                "win_rate_ci_high": "å‹ç‡ CIâ†‘",
                "top8_rate": "Top8 ç‡ %",
                "top8_rate_ci_low": "Top8 CIâ†“",
                "top8_rate_ci_high": "Top8 CIâ†‘",
                "deck_count": "æ¨£æœ¬æ•¸",
            }),
            use_container_width=True, hide_index=True,
        )
    else:
        _show_empty()


elif section == "ğŸ’° æœŸæœ›å€¼ (EV)":
    st.title("ğŸ’° æœŸæœ›å€¼åˆ†æ (Expected Value)")

    st.info(
        "**EV** ï¼ æ¯æ¬¡åƒè³½çš„å¹³å‡é æœŸç©åˆ†\n\n"
        "ç©åˆ†ï¼šå„ªå‹ = 100ã€Top4 = 50ã€Top8 = 25ã€å…¶ä»– = 0\n\n"
        "**Sharpe Ratio** ï¼ EV / Ïƒ â€” è¡¡é‡ã€Œå ±é…¬ / é¢¨éšªã€æ¯”ï¼Œè¶Šé«˜è¶Šå¥½ã€‚"
    )

    results = analyzer.ev_analysis(min_entries)
    if not results:
        _show_empty()
        st.stop()

    df = _make_df(results)

    # â”€â”€ Bar chart â”€â”€
    st.subheader("EV æ’åï¼ˆå‰ 20 åï¼‰")
    top = df.head(20).sort_values("ev")
    st.bar_chart(top.set_index("ç‰Œçµ„")[["ev"]], use_container_width=True)

    # â”€â”€ Risk-Reward scatter â”€â”€
    st.subheader("é¢¨éšªâ€”å ±é…¬æ•£ä½ˆåœ–")
    scatter = df[["ç‰Œçµ„", "ev", "std", "deck_count"]].head(30).copy()
    scatter.columns = ["ç‰Œçµ„", "EV", "Std Dev", "æ¨£æœ¬æ•¸"]
    st.scatter_chart(scatter, x="Std Dev", y="EV", size="æ¨£æœ¬æ•¸",
                     use_container_width=True)

    # â”€â”€ Full table â”€â”€
    st.subheader("å®Œæ•´è³‡æ–™")
    st.dataframe(
        df[["ç‰Œçµ„", "ev", "std", "sharpe", "ev_label",
            "wins", "top4", "top8", "deck_count"]]
        .rename(columns={
            "ev": "EV",
            "std": "Std Dev",
            "sharpe": "Sharpe",
            "ev_label": "ç­‰ç´š",
            "wins": "å„ªå‹",
            "top4": "Top4",
            "top8": "Top8",
            "deck_count": "ç¸½å¥—æ•¸",
        }),
        use_container_width=True, hide_index=True,
    )


elif section == "âš”ï¸ åŒ¹é…é¡¯è‘—æ€§":
    st.title("âš”ï¸ åŒ¹é…é¡¯è‘—æ€§æª¢å®š (Binomial Exact Test)")

    st.info(
        "**é›™å°¾ç²¾ç¢ºäºŒé …æª¢å®š**ï¼šæª¢é©—è§€æ¸¬åˆ°çš„å°æˆ°å‹ç‡æ˜¯å¦é¡¯è‘—åé›¢ 50 %ã€‚\n\n"
        "- â˜… p < 0.01ï¼ˆé«˜åº¦é¡¯è‘—ï¼‰\n"
        "- â˜† p < 0.05ï¼ˆé¡¯è‘—ï¼‰\n"
        "- â€” ä¸é¡¯è‘—ï¼ˆå¯èƒ½åªæ˜¯éš¨æ©Ÿåå·®ï¼‰"
    )

    result = analyzer.matchup_significance()
    pairs = result.get("pairs", [])

    if not pairs:
        _show_empty()
        st.stop()

    # â”€â”€ Summary metric â”€â”€
    sig_count = sum(1 for p in pairs if p["significant"])
    st.metric("é¡¯è‘—åŒ¹é…æ•¸", f"{sig_count} / {len(pairs)}", help="p < 0.05")

    # â”€â”€ Filter toggle â”€â”€
    show_only_sig = st.checkbox("åªé¡¯ç¤ºé¡¯è‘—çµæœ", value=True)
    visible = [p for p in pairs if p["significant"]] if show_only_sig else pairs

    if visible:
        df = pd.DataFrame(visible)
        df["å°æˆ°çµ„åˆ"] = df["archetype1"].map(zh) + " vs " + df["archetype2"].map(zh)
        st.dataframe(
            df[["å°æˆ°çµ„åˆ", "a1_wins", "a2_wins", "total", "win_rate", "p_value", "label"]]
            .rename(columns={
                "a1_wins": "A å‹",
                "a2_wins": "B å‹",
                "total": "ç¸½å ´æ¬¡",
                "win_rate": "A å‹ç‡ %",
                "p_value": "p-value",
                "label": "é¡¯è‘—æ€§",
            }),
            use_container_width=True, hide_index=True,
        )
    else:
        st.info("æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„çµæœ")

    st.caption(f"æª¢å®šæ–¹æ³•ï¼š{result['test']} Â· Î± = {result['threshold']}")
